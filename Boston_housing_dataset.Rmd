
# Boston housing dataset Example

Since GAM did not work well with the Ames housing dataset, we decided to use another dataset and to test the GAM method on it. The new dataset, Boston housing, includes 13 explanatory variables, and the response variable `MEDV`. The following is the description from Kaggle:

1) `CRIM`: per capita crime rate by town

2) `ZN`: proportion of residential land zoned for lots over 25,000 sq.ft.

3) `INDUS`: proportion of non-retail business acres per town

4) `CHAS`: Charles River dummy variable (1 if tract bounds river; 0 otherwise)

5) `NOX`: nitric oxides concentration (parts per 10 million) [parts/10M]

6) `RM`: average number of rooms per dwelling

7) `AGE`: proportion of owner-occupied units built prior to 1940

8) `DIS`: weighted distances to five Boston employment centres

9) `RAD`: index of accessibility to radial highways

10) `TAX`: full-value property-tax rate per $10,000 [$/10k]

11) `PTRATIO`: pupil-teacher ratio by town

12) `B`: The result of the equation B=1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town

13) `LSTAT`: % lower status of the population

Output variable:

1) `MEDV`: Median value of owner-occupied homes in $1000's [k$]

```{r,echo=FALSE,warning=FALSE, include=FALSE}
library(tidyverse)
library(caret)
library(recipes)
library(mgcv)
boston<-read_csv("boston.csv") #load package and dataset
```

```{r}
glimpse(boston)  # p=13
sum(is.na(boston))  # check for missing entries
summary(boston)  # check types of features
nearZeroVar(boston)  # check for near zero variable
```
```{r}
cor(boston)
```


```{r}
# split the dataset

set.seed(013123)   # set seed

index <- createDataPartition(y = boston$MEDV, p = 0.8, list = FALSE)   # consider 70-30 split

boston_train <- boston[index,]   # training data

boston_test <- boston[-index,]   # test data
```



```{r}
# finally, after all preprocessing steps have been decided set up the overall blueprint

boston_recipe <- recipe(MEDV~., data = boston_train)   # set up recipe

# specify feature engineering steps
boston_blueprint <- boston_recipe %>%    
  step_center(all_numeric(), -all_outcomes()) %>%                      # center (subtract mean) all numeric predictors (consider all the numeric predictors except the response)
  step_scale(all_numeric(), -all_outcomes())                     # scale (divide by standard deviation) all numeric predictors                     

# replace step_center and step_scale with step_normalize

boston_prepare <- prep(boston_blueprint, data = boston_train)    # estimate feature engineering parameters based on training data


boston_baked_train <- bake(boston_prepare, new_data = boston_train)   # apply the blueprint to training data for building final/optimal model

boston_baked_test <- bake(boston_prepare, new_data = boston_test)    # apply the blueprint to test data for future use
```

```{r}
tunegrid<-data.frame(method = "GCV.Cp", select = TRUE)
set.seed(111)
boston_model<-train(boston_blueprint,
             data=boston_train,
             method="gam",
             tuneGrid=data.frame(method = "GCV.Cp", select = TRUE), #method indicates the smoothing parameter estimation method, GCV for models with unknown scale parameter and Mallows' Cp/UBRE/AIC for models with known scale; select=TRUE adds extra penalty so that the smoothing parameter estimation can completely remove terms from the model 
             trControl=trainControl(method="cv",number=5)
)
boston_model$results$RMSE

boston_model$finalMo
```
```{r}
# obtain predictions and test set RMSE

boston_final_model <- gam(MEDV~CHAS + RAD + s(ZN) + s(PTRATIO) + s(TAX) + s(INDUS) + 
    s(NOX) + s(B) + s(AGE) + s(DIS) + s(RM) + s(LSTAT) + s(CRIM),data=boston_baked_train) 

boston_final_model_preds<- predict(object = boston_final_model, newdata = boston_baked_test, type = "response")    # obtain predictions

sqrt(mean((boston_final_model_preds - boston_baked_test$MEDV)^2))   # calculate test set RMSE
```

```{r}
coef(boston_final_model)
```


```{r}
summary(boston_final_model)

```

```{r}
plot(boston_final_model, residuals=TRUE,shade = TRUE, shade.col = "lightblue")
```

