
# Boston housing dataset Example

## Data description

Since GAM did not work well with the Ames housing dataset, which output a big RMSE, we decided to use another dataset and to test the GAM method on it again. The new dataset, Boston housing, includes 13 explanatory variables, and the response variable `MEDV`. The following is the description from Kaggle all variables:

Response Variable: 

1) `MEDV`: Median value of owner-occupied homes in `$`1000's [k`$`]


Explanatory variables:

1) `CRIM`: per capita crime rate by town

2) `ZN`: proportion of residential land zoned for lots over 25,000 sq.ft.

3) `INDUS`: proportion of non-retail business acres per town

4) `CHAS`: Charles River dummy variable (1 if tract bounds river; 0 otherwise)

5) `NOX`: nitric oxides concentration (parts per 10 million) [parts/10M]

6) `RM`: average number of rooms per dwelling

7) `AGE`: proportion of owner-occupied units built prior to 1940

8) `DIS`: weighted distances to five Boston employment centres

9) `RAD`: index of accessibility to radial highways

10) `TAX`: full-value property-tax rate per `$`10,000 [`$`/10k]

11) `PTRATIO`: pupil-teacher ratio by town

12) `B`: The result of the equation B=1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town

13) `LSTAT`: % lower status of the population



```{r,echo=FALSE,warning=FALSE, include=FALSE}
# load package and dataset

library(tidyverse)
library(caret)
library(recipes)
library(mgcv)

boston<-read_csv("boston.csv") # load package and dataset
```


### Data Invistigation

```{r}
glimpse(boston)  
summary(boston) 
sum(is.na(boston)) 
nearZeroVar(boston) 
```

The first thing we do is to investigate the dataset. Finding that there are 13 features in total and all of them are numerical variables. There is no NA value in the whole dataset and no zv or nzv features.

```{r}
cor(boston)
```

From the correlation plot, noticing that for variable `TAX` and `INDUS`, `DIS` and `INDUS`, `TAX` and `INDUS`, `NOX` and `INDUS`, `NOX` and `AGE`, `NOX` and `DIS`, `AGE` and `DIS`... are highly correlated variable. (We are saying two variables are highly correlated when their correlation value is greater that 0.7)


### Data Spliting 

```{r}
set.seed(013123)   # set seed

index <- createDataPartition(y = boston$MEDV, p = 0.8, list = FALSE)   # consider 80-20 split

boston_train <- boston[index,]   # training data

boston_test <- boston[-index,]   # test data
```

### Recipt and Blueprint

```{r}
# Set up recipe 
boston_recipe <- recipe(MEDV ~ ., data = boston_train)

# set up blueprint
boston_blueprint <- boston_recipe %>%    
  step_center(all_numeric(), -all_outcomes()) %>%                      # center (subtract mean) all numeric predictors (consider all the numeric predictors except the response)
  step_scale(all_numeric(), -all_outcomes())                     # scale (divide by standard deviation) all numeric predictors                     
```

Since there's no missing value, no zv/nzv features and no categorical variable in `boston` dataset, all we need in blueprint is to standardize the data. 

```{r}
# estimate feature engineering parameters based on training data
boston_prepare <- prep(boston_blueprint, data = boston_train)   

# apply the blueprint to training data for building final/optimal model
boston_baked_train <- bake(boston_prepare, new_data = boston_train)   

# apply the blueprint to test data for future use
boston_baked_test <- bake(boston_prepare, new_data = boston_test)    
```

## Analysis

### Bulid Model

```{r}
set.seed(111)
# implement 5-fold CV with no repeat
cv_specs <- trainControl(method = "cv", number = 5)

# set tunegrid
tunegrid <- data.frame(method = "GCV.Cp", select = TRUE)

# GAM model
boston_model <- train(boston_blueprint,
                      data = boston_train,
                      method = "gam",
                      tuneGrid = data.frame(method = "GCV.Cp", select = TRUE),
                      trControl = cv_specs)
```

We implement CV with no repeat here to ensure the model is not overfitting and is generalizable to new data, which is very important for GAM model.

For the model, Method = "gan" indicates the smoothing parameter estimation method, GCV for models with unknown scale parameter and Mallows' Cp/UBRE/AIC for models with known scale; select=TRUE adds extra penalty so that the smoothing parameter estimation can completely remove terms from the model

### Model's Performance

```{r}
# RMSE
boston_model$results$RMSE

boston_model$finalMo
```

From the result, seeing that the RMSE is very small here, around 4, which indicates GAM model works well with train `boston` dataset. 

The estimated degrees of freedom indicate the complexity of the model, and in this case, the EDF ranges from 0 to 8.392, with a total EDF of 44.8. The EDF values for the smoothing functions indicate the effective number of parameters used to fit the data, and higher EDF values generally indicate more flexible, complex models.

The GCV score is used as a measure of the model's performance because it provides a balance between the model's fit to the data and its complexity. 

### Prediction

```{r}
# obtain predictions and test set RMSE

boston_final_model <- gam(MEDV ~ CHAS + RAD + s(ZN) + s(PTRATIO) + s(TAX) + s(INDUS) + s(NOX) + s(B) + s(AGE) + s(DIS) + s(RM) + s(LSTAT) + s(CRIM), data = boston_baked_train) 

boston_final_model_preds<- predict(object = boston_final_model, newdata = boston_baked_test, type = "response")    # obtain predictions

sqrt(mean((boston_final_model_preds - boston_baked_test$MEDV)^2))   # calculate test set RMSE
```

The test set RMSE is even smaller, which is a good sign. 

Comparing with using GAM model for `ames` dataset, using it for `boston` dataset seems become better a lot. The reason why this happen is because 

```{r}
coef(boston_final_model)
```


```{r}
summary(boston_final_model)
```

```{r}
plot(boston_final_model, residuals=TRUE,shade = TRUE, shade.col = "lightblue")
```

