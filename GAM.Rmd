--- 
title: "CMSC 208 Final Project"
author: "Yi Lu, Shiyi Yang"
date: "`r format(Sys.time(), '%B %d, %Y %H:%M %Z')`"
site: bookdown::bookdown_site
bibliography: references.bib
biblio-style: apalike
link-citations: yes
---

# Introducation

The topic we wish to explore is the Generalized Additive Models. It is a powerful extension of the linear regression model that can capture complex nonlinear relationships between predictors and response variables, which allows for non-linear function of each variable, while maintaining their additivity. So, instead of $y = \beta_0 + \beta_1x_1 + \beta_2x_2+...+\epsilon$, we would have a function of $y = \beta_0 + f_1(x_1) + f_2(x_2) + ... +\epsilon$, where $f(xi)$ represent a (smooth) non-linear function. They can also model interactions between variables and handle different types of data, including continuous, categorical, and ordinal variables. 





<!--chapter:end:index.Rmd-->


# Ames Housing Dataset Example

```{r}
library(tidyverse)
library(caret)
library(recipes)
library(mgcv)
ames<-readRDS("AmesHousing.rds")
```


```{r}
glimpse(ames)  # Knowing that for this dataset n = 881, p = 20-1 = 19.
sum(is.na(ames))    # check for missing entries
summary(ames)  # check types of features, which features have missing entries?
levels(ames$Overall_Qual)   # the levels are NOT properly ordered

# relevel the levels

ames$Overall_Qual <- factor(ames$Overall_Qual, levels = c("Very_Poor", "Poor", "Fair", "Below_Average", 
                                                  "Average", "Above_Average", "Good", "Very_Good", 
                                                  "Excellent", "Very_Excellent"))

levels(ames$Overall_Qual)   # the levels are properly ordered


```

```{r}
# split the dataset

set.seed(013123)   # set seed

index <- createDataPartition(y = ames$Sale_Price, p = 0.8, list = FALSE)   # consider 70-30 split

ames_train <- ames[index,]   # training data

ames_test <- ames[-index,]   # test data
```


```{r}
# investigate nominal categorical predictors 

ames_train %>% count(Neighborhood) %>% arrange(n)   # check frequency of categories
```

```{r}
# finally, after all preprocessing steps have been decided set up the overall blueprint

ames_recipe <- recipe(Sale_Price~., data = ames_train)   # set up recipe

# specify feature engineering steps
ames_blueprint <- ames_recipe %>%    
  step_nzv(Street, Utilities, Pool_Area, Screen_Porch, Misc_Val) %>%   # filter out zv/nzv predictors
  step_impute_mean(Gr_Liv_Area) %>%                                    # impute missing entries
  step_integer(Overall_Qual) %>%                                       # numeric conversion of levels of the predictors   
  step_center(all_numeric(), -all_outcomes()) %>%                      # center (subtract mean) all numeric predictors (consider all the numeric predictors except the response)
  step_scale(all_numeric(), -all_outcomes()) %>%                       # scale (divide by standard deviation) all numeric predictors
  step_other(Neighborhood, threshold = 0.01, other = "other") %>%      # lumping required predictors
  step_dummy(all_nominal(), one_hot = FALSE)                            # one-hot/dummy encode nominal categorical predictors

# replace step_center and step_scale with step_normalize

ames_prepare <- prep(ames_blueprint, data = ames_train)    # estimate feature engineering parameters based on training data


ames_baked_train <- bake(ames_prepare, new_data = ames_train)   # apply the blueprint to training data for building final/optimal model

ames_baked_test <- bake(ames_prepare, new_data = ames_test)    # apply the blueprint to test data for future use
```




```{r}
set.seed(111)
ames_model<-train(ames_blueprint,
             data=ames_train,
             method="gam",
             tuneGrid=data.frame(method = "GCV.Cp", select = TRUE),  
             trControl=trainControl(method="cv",number=5)
)
ames_model$results$RMSE

ames_model$finalMo
```


```{r}
  
# build final model
ames_final_model <- gam(Sale_Price~Garage_Type_BuiltIn + Garage_Type_Detchd + Garage_Type_No_Garage + Neighborhood_College_Creek + Neighborhood_Old_Town + Neighborhood_Edwards + Neighborhood_Somerset + Neighborhood_Northridge_Heights + Neighborhood_Gilbert + Neighborhood_Sawyer + MS_SubClass_One_and_Half_Story_Finished_All_Ages + MS_SubClass_Two_Story_1946_and_Newer + MS_SubClass_Duplex_All_Styles_and_Ages + 
MS_SubClass_One_Story_PUD_1946_and_Newer + Garage_Cars + Overall_Qual + s(TotRms_AbvGrd) + s(Lot_Frontage) + s(Year_Built) + s(Open_Porch_SF) + s(Second_Flr_SF) + s(Garage_Area) + s(Gr_Liv_Area) + s(First_Flr_SF) + s(Lot_Area) ,data=ames_baked_train) 

# final model predication
ames_final_model_preds<- predict(object = ames_final_model, newdata = ames_baked_test, type = "response")  

sqrt(mean((ames_final_model_preds - ames_baked_test$Sale_Price)^2))   # calculate test set RMSE
```




```{r}
plot(ames_final_model, residuals=TRUE,shade = TRUE, shade.col = "lightblue")
```


Noticing that the RMSE for both train dataset and test dataset are all large, especailly for test dataset, which means the GAM model didn't work well for ames housing dataset. In order to show a better performace, we found another dataset, boston housing, to have a try. 

```{r}
ames_final_model2 <- gam(Sale_Price~ s(Gr_Liv_Area) + 
    s(First_Flr_SF) + s(Lot_Area) ,data=ames_baked_train) 
ames_final_model_preds2<- predict(object = ames_final_model2, newdata = ames_baked_test, type = "response")    # obtain predictions

sqrt(mean((ames_final_model_preds2 - ames_baked_test$Sale_Price)^2))   # calculate test set RMSE
```


## Boston Housing Dataset Example



# Conclusion


```{r}
ggplot(ames,aes(x=Gr_Liv_Area,y=Sale_Price))+geom_point()+geom_smooth()
```

```{r}
gam_mod <- gam(Sale_Price ~ s(Gr_Liv_Area), data = ames)
plot(gam_mod)
```





```{r}
ames_final_model2 <- gam(Sale_Price~ s(Gr_Liv_Area) + 
    s(First_Flr_SF) + s(Lot_Area) ,data=ames_baked_train) 
ames_final_model_preds2<- predict(object = ames_final_model2, newdata = ames_baked_test, type = "response")    # obtain predictions

sqrt(mean((ames_final_model_preds2 - ames_baked_test$Sale_Price)^2))   # calculate test set RMSE
```












<!--chapter:end:208_project.Rmd-->

---
title: "CMSC/LING/STAT 208: Final Project - GAMs"
author: "Yi Lu, Shiyi Yang"
output: html_document
---

# Introducation

The topic we wish to explore is the Generalized Additive Models. It is a powerful extension of the linear regression model that can capture complex nonlinear relationships between predictors and response variables, which allows for non-linear function of each variable, while maintaining their additivity. So, instead of $y = \beta_0 + \beta_1x_1 + \beta_2x_2+...+\epsilon$, we would have a function of $y = \beta_0 + f_1(x_1) + f_2(x_2) + ... +\epsilon$, where $f(xi)$ represent a (smooth) non-linear function. They can also model interactions between variables and handle different types of data, including continuous, categorical, and ordinal variables. 


# Example

## Ames Housing Dataset Example

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(caret)
library(recipes)
library(mgcv)
ames<-readRDS("AmesHousing.rds")
```


```{r}
glimpse(ames)  # Knowing that for this dataset n = 881, p = 20-1 = 19.
sum(is.na(ames))    # check for missing entries
summary(ames)  # check types of features, which features have missing entries?
levels(ames$Overall_Qual)   # the levels are NOT properly ordered

# relevel the levels

ames$Overall_Qual <- factor(ames$Overall_Qual, levels = c("Very_Poor", "Poor", "Fair", "Below_Average", 
                                                  "Average", "Above_Average", "Good", "Very_Good", 
                                                  "Excellent", "Very_Excellent"))

levels(ames$Overall_Qual)   # the levels are properly ordered


```

```{r}
# split the dataset

set.seed(013123)   # set seed

index <- createDataPartition(y = ames$Sale_Price, p = 0.8, list = FALSE)   # consider 70-30 split

ames_train <- ames[index,]   # training data

ames_test <- ames[-index,]   # test data
```


```{r}
# investigate nominal categorical predictors 

ames_train %>% count(Neighborhood) %>% arrange(n)   # check frequency of categories
```

```{r}
# finally, after all preprocessing steps have been decided set up the overall blueprint

ames_recipe <- recipe(Sale_Price~., data = ames_train)   # set up recipe

# specify feature engineering steps
ames_blueprint <- ames_recipe %>%    
  step_nzv(Street, Utilities, Pool_Area, Screen_Porch, Misc_Val) %>%   # filter out zv/nzv predictors
  step_impute_mean(Gr_Liv_Area) %>%                                    # impute missing entries
  step_integer(Overall_Qual) %>%                                       # numeric conversion of levels of the predictors   
  step_center(all_numeric(), -all_outcomes()) %>%                      # center (subtract mean) all numeric predictors (consider all the numeric predictors except the response)
  step_scale(all_numeric(), -all_outcomes()) %>%                       # scale (divide by standard deviation) all numeric predictors
  step_other(Neighborhood, threshold = 0.01, other = "other") %>%      # lumping required predictors
  step_dummy(all_nominal(), one_hot = FALSE)                            # one-hot/dummy encode nominal categorical predictors

# replace step_center and step_scale with step_normalize

ames_prepare <- prep(ames_blueprint, data = ames_train)    # estimate feature engineering parameters based on training data


ames_baked_train <- bake(ames_prepare, new_data = ames_train)   # apply the blueprint to training data for building final/optimal model

ames_baked_test <- bake(ames_prepare, new_data = ames_test)    # apply the blueprint to test data for future use
```




```{r}
set.seed(111)
ames_model<-train(ames_blueprint,
             data=ames_train,
             method="gam",
             tuneGrid=data.frame(method = "GCV.Cp", select = TRUE),  
             trControl=trainControl(method="cv",number=5)
)
ames_model$results$RMSE

ames_model$finalMo
```


```{r}
  
# build final model
ames_final_model <- gam(Sale_Price~Garage_Type_BuiltIn + Garage_Type_Detchd + Garage_Type_No_Garage + Neighborhood_College_Creek + Neighborhood_Old_Town + Neighborhood_Edwards + Neighborhood_Somerset + Neighborhood_Northridge_Heights + Neighborhood_Gilbert + Neighborhood_Sawyer + MS_SubClass_One_and_Half_Story_Finished_All_Ages + MS_SubClass_Two_Story_1946_and_Newer + MS_SubClass_Duplex_All_Styles_and_Ages + 
MS_SubClass_One_Story_PUD_1946_and_Newer + Garage_Cars + Overall_Qual + s(TotRms_AbvGrd) + s(Lot_Frontage) + s(Year_Built) + s(Open_Porch_SF) + s(Second_Flr_SF) + s(Garage_Area) + s(Gr_Liv_Area) + s(First_Flr_SF) + s(Lot_Area) ,data=ames_baked_train) 

# final model predication
ames_final_model_preds<- predict(object = ames_final_model, newdata = ames_baked_test, type = "response")  

sqrt(mean((ames_final_model_preds - ames_baked_test$Sale_Price)^2))   # calculate test set RMSE
```




```{r}
plot(ames_final_model, residuals=TRUE,shade = TRUE, shade.col = "lightblue")
```


Noticing that the RMSE for both train dataset and test dataset are all large, especailly for test dataset, which means the GAM model didn't work well for ames housing dataset. In order to show a better performace, we found another dataset, boston housing, to have a try. 

```{r}
ames_final_model2 <- gam(Sale_Price~ s(Gr_Liv_Area) + 
    s(First_Flr_SF) + s(Lot_Area) ,data=ames_baked_train) 
ames_final_model_preds2<- predict(object = ames_final_model2, newdata = ames_baked_test, type = "response")    # obtain predictions

sqrt(mean((ames_final_model_preds2 - ames_baked_test$Sale_Price)^2))   # calculate test set RMSE
```


## Boston Housing Dataset Example



# Conclusion


```{r}
ggplot(ames,aes(x=Gr_Liv_Area,y=Sale_Price))+geom_point()+geom_smooth()
```

```{r}
gam_mod <- gam(Sale_Price ~ s(Gr_Liv_Area), data = ames)
plot(gam_mod)
```





```{r}
ames_final_model2 <- gam(Sale_Price~ s(Gr_Liv_Area) + 
    s(First_Flr_SF) + s(Lot_Area) ,data=ames_baked_train) 
ames_final_model_preds2<- predict(object = ames_final_model2, newdata = ames_baked_test, type = "response")    # obtain predictions

sqrt(mean((ames_final_model_preds2 - ames_baked_test$Sale_Price)^2))   # calculate test set RMSE
```












<!--chapter:end:ames_housing_dataset.Rmd-->


# Boston housing dataset Example

Since GAM did not work well with the Ames housing dataset, we decided to use another dataset and to test the GAM method on it. The new dataset, Boston housing, includes 13 explanatory variables, and the response variable `MEDV`. The following is the description from Kaggle:

Output variable:

1) `MEDV`: Median value of owner-occupied homes in $1000's [k$]

Explanatory variables:

1) `CRIM`: per capita crime rate by town

2) `ZN`: proportion of residential land zoned for lots over 25,000 sq.ft.

3) `INDUS`: proportion of non-retail business acres per town

4) `CHAS`: Charles River dummy variable (1 if tract bounds river; 0 otherwise)

5) `NOX`: nitric oxides concentration (parts per 10 million) [parts/10M]

6) `RM`: average number of rooms per dwelling

7) `AGE`: proportion of owner-occupied units built prior to 1940

8) `DIS`: weighted distances to five Boston employment centres

9) `RAD`: index of accessibility to radial highways

10) `TAX`: full-value property-tax rate per $10,000 [$/10k]

11) `PTRATIO`: pupil-teacher ratio by town

12) `B`: The result of the equation B=1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town

13) `LSTAT`: % lower status of the population


```{r,echo=FALSE,warning=FALSE, include=FALSE}
library(tidyverse)
library(caret)
library(recipes)
library(mgcv)
boston<-read_csv("boston.csv") #load package and dataset
```

Just as before, we first investigate the dataset to see if there's any missing entries, non-numeric variables, or ZV/NZV features.

```{r}
glimpse(boston)  # p=13
sum(is.na(boston))  # check for missing entries
summary(boston)  # check types of features
nearZeroVar(boston)  # check for near zero variable
```
```{r}
cor(boston)
```


```{r}
# split the dataset

set.seed(013123)   # set seed

index <- createDataPartition(y = boston$MEDV, p = 0.8, list = FALSE)   # consider 70-30 split

boston_train <- boston[index,]   # training data

boston_test <- boston[-index,]   # test data
```



```{r}
# finally, after all preprocessing steps have been decided set up the overall blueprint

boston_recipe <- recipe(MEDV~., data = boston_train)   # set up recipe

# specify feature engineering steps
boston_blueprint <- boston_recipe %>%    
  step_center(all_numeric(), -all_outcomes()) %>%                      # center (subtract mean) all numeric predictors (consider all the numeric predictors except the response)
  step_scale(all_numeric(), -all_outcomes())                     # scale (divide by standard deviation) all numeric predictors                     

# replace step_center and step_scale with step_normalize

boston_prepare <- prep(boston_blueprint, data = boston_train)    # estimate feature engineering parameters based on training data


boston_baked_train <- bake(boston_prepare, new_data = boston_train)   # apply the blueprint to training data for building final/optimal model

boston_baked_test <- bake(boston_prepare, new_data = boston_test)    # apply the blueprint to test data for future use
```

```{r}
tunegrid<-data.frame(method = "GCV.Cp", select = TRUE)
set.seed(111)
boston_model<-train(boston_blueprint,
             data=boston_train,
             method="gam",
             tuneGrid=data.frame(method = "GCV.Cp", select = TRUE), #method indicates the smoothing parameter estimation method, GCV for models with unknown scale parameter and Mallows' Cp/UBRE/AIC for models with known scale; select=TRUE adds extra penalty so that the smoothing parameter estimation can completely remove terms from the model 
             trControl=trainControl(method="cv",number=5)
)
boston_model$results$RMSE

boston_model$finalMo
```
```{r}
# obtain predictions and test set RMSE

boston_final_model <- gam(MEDV~CHAS + RAD + s(ZN) + s(PTRATIO) + s(TAX) + s(INDUS) + 
    s(NOX) + s(B) + s(AGE) + s(DIS) + s(RM) + s(LSTAT) + s(CRIM),data=boston_baked_train) 

boston_final_model_preds<- predict(object = boston_final_model, newdata = boston_baked_test, type = "response")    # obtain predictions

sqrt(mean((boston_final_model_preds - boston_baked_test$MEDV)^2))   # calculate test set RMSE
```

```{r}

# obtain predictions and test set RMSE

boston_final_model2 <- gam(MEDV~ s(ZN) + s(PTRATIO) + s(TAX) + s(INDUS) + 
    s(NOX) + s(B) + s(AGE) + s(DIS) + s(RM) + s(LSTAT) + s(CRIM),data=boston_baked_train) 

boston_final_model_preds2<- predict(object = boston_final_model2, newdata = boston_baked_test, type = "response")    # obtain predictions

sqrt(mean((boston_final_model_preds2 - boston_baked_test$MEDV)^2))   # calculate test set RMSE
```


```{r}
coef(boston_final_model)
```


```{r}
summary(boston_final_model)

```

```{r}
plot(boston_final_model, residuals=TRUE,shade = TRUE, shade.col = "lightblue")
```


<!--chapter:end:Boston_housing_dataset.Rmd-->


# Conclusion





<!--chapter:end:Conclusion.Rmd-->

