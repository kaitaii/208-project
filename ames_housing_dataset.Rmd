
# Ames Housing Dataset Example


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Data Description:

First, we use the `ames` dataset that we used in class, since we want to first learn how to apply this model and then do further investigation. 

```{r,echo=FALSE,warning=FALSE, include=FALSE}
library(tidyverse)
library(caret)
library(recipes)
library(mgcv)
ames<-readRDS("AmesHousing.rds")
```

## Preparation Steps

### Data Investigation

Just as before, we first investigate the dataset to see if there's any missing entries, non-numeric variables, or ZV/NZV features.

```{r}
glimpse(ames)
sum(is.na(ames))  
summary(ames)  
nearZeroVar(ames, saveMetrics = TRUE)

levels(ames$Overall_Qual) 

# relevel the levels

ames$Overall_Qual <- factor(ames$Overall_Qual, levels = c("Very_Poor", "Poor", "Fair", "Below_Average", 
                                                  "Average", "Above_Average", "Good", "Very_Good", 
                                                  "Excellent", "Very_Excellent"))

levels(ames$Overall_Qual)   # the levels are properly ordered


```

Finding that there are 19 features in total and 13 of them are numerical variables, 6 of them are categorical variables. For the ordinal categorical variables `Overall_Qual`, finding that the level is not in order, hence, we relevel the level for this variable. Further, there're 113 NA values and 5 nzv features in the whole dataset. Those are things we need to deal within blueprint.

### Data Spliting

```{r}
set.seed(013123)

index <- createDataPartition(y = ames$Sale_Price, p = 0.8, list = FALSE)   # consider 80-20 split

ames_train <- ames[index,]   # training data

ames_test <- ames[-index,]   # test data

# investigate nominal categorical predictors 

ames_train %>% count(Neighborhood) %>% arrange(n)   # check frequency of categories
```

## Recipt and Blueprint

After all preprocessing steps have been decided set up the overall blueprint.

```{r}
# set up recipe
ames_recipe <- recipe(Sale_Price~., data = ames_train) 

# specify feature engineering steps
ames_blueprint <- ames_recipe %>%    
  step_nzv(Street, Utilities, Pool_Area, Screen_Porch, Misc_Val) %>%  
  step_impute_mean(Gr_Liv_Area) %>%                                   
  step_integer(Overall_Qual) %>%                                       
  step_center(all_numeric(), -all_outcomes()) %>%                      
  step_scale(all_numeric(), -all_outcomes()) %>%                      
  step_other(Neighborhood, threshold = 0.01, other = "other") %>%      
  step_dummy(all_nominal(), one_hot = FALSE)                            
```

Within the blueprint, we first filter out the zv/nzv predictors, and impute the missing entries. Then, we do numeric conversion of level of ordinal categorical variable `Overall_Qual`. Following with the data standardization step and lumping step. Finally, do the one-hot/dummy encode of nominal categorical variables.

```{r}
# estimate feature engineering parameters based on training data
ames_prepare <- prep(ames_blueprint, data = ames_train)   

# apply the blueprint to training data for building final/optimal model
ames_baked_train <- bake(ames_prepare, new_data = ames_train) 

# apply the blueprint to test data for future use
ames_baked_test <- bake(ames_prepare, new_data = ames_test)    
```

## Analysis

### Bulid Model

```{r}
set.seed(111)
# implement 5-fold CV repeated 5 times
cv_specs <- trainControl(method = "repeatedcv", number = 5, repeats=5)

# set tunegrid
tunegrid <- data.frame(method = "GCV.Cp", select = TRUE)

# GAM model
ames_model<-train(ames_blueprint,
             data = ames_train,
             method = "gam",
             tuneGrid = tunegrid,  
             trControl = cv_specs)

```

We implement 5 fold CV with 5 repeats here to ensure the model is not overfitting and is generalizable to new data, which is very important for GAM model.

For the model, Method = "gam" indicates the smoothing parameter estimation method, GCV for models with unknown scale parameter and Mallows' Cp/UBRE/AIC for models with known scale; select=TRUE adds extra penalty so that the smoothing parameter estimation can completely remove terms from the model


### Model's Performance

```{r}
ames_model$results$RMSE

ames_model$finalMo
```

Here we could see that the RMSE is 70421.17, which is pretty high, probably due to the size of the dataset being big. We could also look at the formula of the final model generated from training. It shows that out of the 53 variables, only 9 of the variables have a non-parametric relationship with the response. This could also be the reason for the high RMSE.

## Final Model

### Prediction on Test Dataset

```{r}
# build final model
ames_final_model <- gam(Sale_Price~ Garage_Type_BuiltIn + Garage_Type_Detchd + Garage_Type_No_Garage +  Neighborhood_College_Creek + Neighborhood_Old_Town + Neighborhood_Edwards +  Neighborhood_Somerset + Neighborhood_Northridge_Heights + 
    Neighborhood_Gilbert + Neighborhood_Sawyer + MS_SubClass_One_and_Half_Story_Finished_All_Ages +
    MS_SubClass_Two_Story_1946_and_Newer + MS_SubClass_Duplex_All_Styles_and_Ages + 
    MS_SubClass_One_Story_PUD_1946_and_Newer + Garage_Cars + 
    Overall_Qual + s(TotRms_AbvGrd) + s(Lot_Frontage) + s(Year_Built) + 
    s(Open_Porch_SF) + s(Second_Flr_SF) + s(Garage_Area) + s(Gr_Liv_Area) + 
    s(First_Flr_SF) + s(Lot_Area),data=ames_baked_train) 
ames_final_model_preds<- predict(object = ames_final_model, newdata = ames_baked_test, type = "response")    # obtain predictions

sqrt(mean((ames_final_model_preds- ames_baked_test$Sale_Price)^2))   # calculate test set RMSE
```

Using the formula provided from training, we tried to fit the GAM model. The RMSE of the final model is 195576.6, compared to 70421.17 previously. Obviously, this is not ideal, since now the RMSE is more than two times higher. Why?

```{r}
plot(ames_final_model, residuals=TRUE,shade = TRUE, shade.col = "lightblue",pch = 1, cex = 0.5)
```

Here we have the residual plot of those variables that had applied splines function, and the blue shades represent the 95% confidence interval. 
From the graphs for Gr_Liv_Area and Lot_Area, we could see that the tails are drawn to the noises, letting it change the slope, which should not be happening. 

In order to create a well-fit final model, we have to use the smoothing parameters Î» and k. 
```{r}
gam.check(ames_final_model)
```







```{r}
plot(ames_final_model, residuals=TRUE,shade = TRUE, shade.col = "lightblue")
```


Noticing that the RMSE for both train dataset and test dataset are all large, especailly for test dataset, which means the GAM model didn't work well for ames housing dataset. In order to show a better performance, we found another dataset, boston housing, to have a try. 




```{r}
# build final model
ames_final_model <- gam(Sale_Price~Garage_Type_BuiltIn + Garage_Type_Detchd + Garage_Type_No_Garage + Neighborhood_College_Creek + Neighborhood_Old_Town + Neighborhood_Edwards + Neighborhood_Somerset + Neighborhood_Northridge_Heights + Neighborhood_Gilbert + Neighborhood_Sawyer + MS_SubClass_One_and_Half_Story_Finished_All_Ages + MS_SubClass_Two_Story_1946_and_Newer + MS_SubClass_Duplex_All_Styles_and_Ages + 
MS_SubClass_One_Story_PUD_1946_and_Newer + s(Garage_Cars,k=5) + s(Overall_Qual,k=9) + s(TotRms_AbvGrd,k=9) + s(Lot_Frontage,k=9) + s(Year_Built,sp=0.1,k=6) + s(Open_Porch_SF,k=9) + s(Second_Flr_SF,k=9) + s(Garage_Area,sp=1,k=9) + s(Gr_Liv_Area,sp=1,k=9) + s(First_Flr_SF,sp=-0.001,k=3) + s(Lot_Area,sp=1,k=4) ,data=ames_baked_train) 
```



## Only splines?

```{r}
ames_final_model2 <- gam(Sale_Price~ s(Gr_Liv_Area) + 
    s(First_Flr_SF) + s(Lot_Area) ,data=ames_baked_train) 
ames_final_model_preds2<- predict(object = ames_final_model2, newdata = ames_baked_test, type = "response")    # obtain predictions

sqrt(mean((ames_final_model_preds2 - ames_baked_test$Sale_Price)^2))   # calculate test set RMSE
```











